# 4 카프카의 내부 동작 원리와 구현

## 4.1 카프카 리플리케이션

- 안정성 확보를 위해 설계된 동작

### 4.1.1 리플리케이션 동작 개요

- 토픽 생성시 `replicatio factor` 옵션 필수 설정
- 해당 옵션 수 만큼 리플리케이션 생성, 브로커 장애시 남은 브로커가 클라이언트의 요청을 처리할 수 있다

### 4.1.2 리더와 팔로워

- 리더는 리플리케이션중 하나가 선정, 모든 읽기와 쓰기 작업을 진행
  - 프로듀서는 리더에게만 메세지를 보냄
  - 컨슈머는 리더에게서만 메세지를 가져옴
- 팔로워는 리더가 새로운 메세지를 받았는지 확인 / 복제

### 4.1.3 복제 유지와 커밋

- 리더와 팔로워는 ISR(InSyncReplica) 라는 논리적 그룹으로 묶임
- ISR에 속한 팔로워들만이 리플리케이션 대상이 될 수 있다
- ISR의 팔로워는 데이터 일치 유지를 위해 리더의 데이터를 따라감
  - 만약 따라가지 못하면, 데이터 정합성과 메세지 손실등이 발생할 수 있음
- 리더는 팔로워들의 리플리케이션 동작을 감시
  - 특정 주기동안 복제 요청을 하지 않는 팔로워는 ISR에서 제외
  - ISR은 토픽 상세보기 에서 확인 가능
- ISR내부의 팔로워의 복제가 완료되면 리더는 내부적으로 커밋
  - 마지막 커밋 오프셋 위치는 하이워터마크 라고 부른다
- 커밋된 메세지만 컨슈머가 읽기 가능
  - 메세지의 일관성 유지
- 커밋 오프셋은 `replication-offset-checkpoint` 파일에 저장
  - `topic partition commit` 순으로 표시
  - 다른 브로커들과 비교하여 직접 확인 가능

### 4.1.4 리더와 팔로워의 단계별 리플리케이션 동작

- 래빗MQ 트랜잭션 모드와의 비교
  - 모든 미러(팔로워)가 메세지에 대한 ACK(메세지를 받았는지)을 리더에게 리턴
- 카프카는 ACK 통신을 제거
  - 팔로워가 요청하는 리플리케이션의 오프셋을 보고 확인
  - 리더가 push 하는 방식이 아닌 팔로워가 pull하는 방식
  - 리플리케이션의 부하가 줄어든다

### 4.1.5 리더에포크와 복구

- 리더에포크
  - 카프카의 복구 동작을 할 때 메세지의 일관성을 유지하기 위한 용도로 사용
- 팔로워에 장에가 생길시, 하이워터마크보다 높은 메세지는 신뢰할 수 없다고 판단하여 삭제
- 리더에포크를 사용할 시 리더에 리더에포크 요청
  - 삭제하기전, 리더에포크를 통해 하이워터마크를 조정

## 4.2 컨트롤러

- 리더 선출을 맡는 역할
- 하나의 브로커가 컨트롤러 역할을 맡게됨
- 파티션의 ISR 리스트 중 리더 선출
  - ISR 리스트는 주키퍼에 저장
- 브로커 실패 감지시 ISR리스트 중 하나를 파니션 리더로 선출, 모든 브로커에 전달
- 제어된 종료와 급작스러운 종료의 차이
  - 다운타임(downtime)
  - 제어된 종료
    - 다운타임의 최소화
    - 로그를 디스크에 동기화, 종료로 로그 복구 시간이 짧음
    - `controlled.shutdown.enable = true` 로 설정
    - `kafka-config.sh --broker [id]` 로 현재옵션 확인 가능
  - 장애로인한 갑작스러운 장애
    - 컨트롤러가 파티션별로 순차적으로 리더를 선정
    - 마지막 파티션의 다운타임이 길어짐

## 4.3 로그(로그 세그먼트)

- 카프카의 토픽에 들어오는 메세지는 세그먼트(로그 세그먼트) 파일에 저장
  - 내용, 정보가 같이 저장
- 로그 세그먼트의 최대 크기 1GB
  - 최대 크기를 넘어갈경우 롤링
  - 해당 세그먼트 파일을 클로즈하고 새로운 로그 세그먼트 생성
- 로그 세그먼트 관리 방법
  - 로그 세그먼트 삭제
  - 컴팩션

### 4.3.1 로그 세그먼트 삭제

- 로그 세그먼트 삭제 옵션
  - `serer.properties`
  - `log.cleanup.policy = delete`
- 옵션 따로 적용하지 않을 시 기본으로 로그 세그먼트 삭제 적용
- `retention.ms` 옵션으로 세그먼트 보관 시간 적용
- `retention.bytes` 세그먼트 크기 기준 적용
- 로그 세그먼트 파일의 이름은 오프셋 시작 번호

### 4.3.2 로그 세그먼트 컴팩션

- 현재 활성화된 세그먼트 제외하고 나머지 컴팩션
- 메세지 키를 기준으로 마지막 데이터만 보관
- 로그 컴팩션의 예시중 하나는 `__consumer_offset` 토픽
- `__consumer_offset`
  - 카프카 내부 토픽
  - 컨슈머 그룹 정보를 저장
  - key(컨슈머 그룹명, 토픽명), value(오프셋 커밋 정보) 형태로 저장됨
- 컨슈머 그룹은 마지막 커밋된 오프셋 정보가 중요하므로 이전의 정보는 삭제되어도 무방
- 컴팩션은 가장 마지막 값이 필요한 경우 사용
  - ex) 현재 구매 상태를 보여주는 상황
- 빠른 장애 복구
- 컴팩션 작업중 과도한 입출력 부하가 발생할 수 있음
  - 브로커 리소스 모니터링
- 로그 컴팩션 관련 옵션
  - `cleanup.policy compact`
    - 토픽 옵션으로 적용
    - 토픽 레벨 로그 컴팩션 설정
  - `log.cleanup.policy compact`
    - 브로커 설정
    - 브로커 레벨 로그 컴팩션을 설정
  - `log.cleaner.mi.compaction.lag.ms 0`
    - 브로커 설정
    - 컴팩션 전 경과되어야할 최소 시간 지정
    - 지정X, 마지막 세그먼트를 제외하고 모든 세그먼트를 컴팩션
  - `log.cleaner.max.compaction.lag.ms 9223372036854775807`
    - 브로커 설정
    - 컴팩션 전 경과되어야할 최대 시간
  - `log.cleaner.min.cleanable.ratio 0.5`
    - 브로커 설정
    - 압축되지 않은 부분(dirty), 전체 로그대비 더티 비율이 '옵션값'을 넘으면 로그 컴팩션 실행
